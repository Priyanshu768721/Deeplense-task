{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11003106,"sourceType":"datasetVersion","datasetId":6849621}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport gc\nimport glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.metrics import structural_similarity as ssi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:48:46.247080Z","iopub.execute_input":"2025-03-17T09:48:46.247393Z","iopub.status.idle":"2025-03-17T09:48:49.493263Z","shell.execute_reply.started":"2025-03-17T09:48:46.247366Z","shell.execute_reply":"2025-03-17T09:48:49.492549Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def get_npy_file_paths(directory):\n    return sorted(glob.glob(os.path.join(directory, \"*.npy\")))\n\n# load file paths \nlr_dir = \"/kaggle/input/dataset-3a/Dataset/LR\"  \nhr_dir = \"/kaggle/input/dataset-3a/Dataset/HR\"\nlr_path =  get_npy_file_paths(lr_dir)\nhr_path = get_npy_file_paths(hr_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:48:49.494206Z","iopub.execute_input":"2025-03-17T09:48:49.494679Z","iopub.status.idle":"2025-03-17T09:48:49.540761Z","shell.execute_reply.started":"2025-03-17T09:48:49.494653Z","shell.execute_reply":"2025-03-17T09:48:49.540178Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"lr_path_tr,lr_path_test = train_test_split(lr_path,train_size=0.9, shuffle=True,random_state=42)\nhr_path_tr,hr_path_test = train_test_split(hr_path,train_size=0.9, shuffle=True,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:48:49.541900Z","iopub.execute_input":"2025-03-17T09:48:49.542150Z","iopub.status.idle":"2025-03-17T09:48:49.550483Z","shell.execute_reply.started":"2025-03-17T09:48:49.542130Z","shell.execute_reply":"2025-03-17T09:48:49.549650Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# custom dataset class\nclass SRDataset(Dataset):\n    def __init__(self, lr_path, hr_path, transform=None):\n        self.lr_path = lr_path\n        self.hr_path = hr_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.lr_path)\n\n    def __getitem__(self, idx):\n        lr = np.load(self.lr_path[idx]).astype(np.float32)  # Low-resolution image\n        hr = np.load(self.hr_path[idx]).astype(np.float32)  # High-resolution image\n\n        if self.transform:\n            lr = self.transform(torch.tensor(lr, dtype=torch.float32))  \n            hr = self.transform(torch.tensor(hr, dtype=torch.float32))\n        return lr, hr\n\n# Define transforms for normalization (-1 to 1 range)\ntransform = transforms.Compose([\n    # transforms.Normalize(mean=[lr_mean], std=[lr_std])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:48:49.551488Z","iopub.execute_input":"2025-03-17T09:48:49.551773Z","iopub.status.idle":"2025-03-17T09:48:49.565065Z","shell.execute_reply.started":"2025-03-17T09:48:49.551752Z","shell.execute_reply":"2025-03-17T09:48:49.564350Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Loading  dataset\n\ndataset_train = SRDataset(lr_path_tr, hr_path_tr, transform=transform)\ndataset_test = SRDataset(lr_path_test,hr_path_test,transform=transform)\ntrain_dataloader = DataLoader(dataset_train, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(dataset_test,batch_size=16,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:48:49.565767Z","iopub.execute_input":"2025-03-17T09:48:49.566043Z","iopub.status.idle":"2025-03-17T09:48:49.579552Z","shell.execute_reply.started":"2025-03-17T09:48:49.566012Z","shell.execute_reply":"2025-03-17T09:48:49.578804Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# RCAN Model\n# Channel Attention (CA) Block\nclass CALayer(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(CALayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv_du = nn.Sequential(\n            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        y = self.avg_pool(x)\n        y = self.conv_du(y)\n        return x * y\n\n# Residual Channel Attention Block (RCAB)\nclass RCAB(nn.Module):\n    def __init__(self, channel):\n        super(RCAB, self).__init__()\n        self.conv1 = nn.Conv2d(channel, channel, 3, padding=1, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(channel, channel, 3, padding=1, bias=True)\n        self.ca = CALayer(channel)\n    \n    def forward(self, x):\n        res = self.conv1(x)\n        res = self.relu(res)\n        res = self.conv2(res)\n        res = self.ca(res)\n        return res + x  # Residual connection\n\n# Residual Group (RG)\nclass ResidualGroup(nn.Module):\n    def __init__(self, channel, num_rcab):\n        super(ResidualGroup, self).__init__()\n        self.rcabs = nn.Sequential(*[RCAB(channel) for _ in range(num_rcab)])\n        self.conv = nn.Conv2d(channel, channel, 3, padding=1, bias=True)\n    \n    def forward(self, x):\n        res = self.rcabs(x)\n        res = self.conv(res)\n        return res + x\n\n# RCAN Model\nclass RCAN(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, num_features=64, num_rg=2, num_rcab=4):\n        super(RCAN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1)\n        \n        self.residual_groups = nn.Sequential(*[ResidualGroup(num_features, num_rcab) for _ in range(num_rg)])\n        self.conv2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=1)\n        \n        self.upsample = nn.Sequential(\n            nn.Conv2d(num_features, num_features * 4, kernel_size=3, padding=1),\n            nn.PixelShuffle(2),\n            nn.Conv2d(num_features, out_channels, kernel_size=3, padding=1)\n        )\n    \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.residual_groups(x1)\n        x3 = self.conv2(x2) + x1  # Global residual connection\n        out = self.upsample(x3)\n        return torch.clamp(out, 0, 1)\n\n# Example usage\nif __name__ == \"__main__\":\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = RCAN().to(device)\n    x = torch.randn(1, 1, 32, 32).to(device)  # Example input (LR image)\n    y = model(x)\n    print(y.shape)  # Output should be a high-resolution image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T09:50:39.930942Z","iopub.execute_input":"2025-03-17T09:50:39.931324Z","iopub.status.idle":"2025-03-17T09:50:40.311740Z","shell.execute_reply.started":"2025-03-17T09:50:39.931298Z","shell.execute_reply":"2025-03-17T09:50:40.311012Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 64, 64])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n\n# Initialize the model\nrcan = RCAN().to(device)  # Make sure RCAN is defined\n\n# Define loss function (Pixel-wise loss)\ncriterion_pixel = nn.MSELoss()\n\n# Define optimizer\noptimizer = optim.Adam(rcan.parameters(), lr=1e-4)\n\nnum_epochs = 10  # Number of training epochs\nfor epoch in range(num_epochs):\n    # Training Phase\n    rcan.train()\n    train_loss = 0.0\n    for lr, hr in tqdm(train_dataloader):\n        lr, hr = lr.to(device), hr.to(device)\n\n        # Forward pass\n        fake_hr = rcan(lr)\n        \n        # Compute pixel-wise loss\n        loss = criterion_pixel(fake_hr, hr)\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Evaluation Phase (on test dataset)\n    rcan.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for lr, hr in test_dataloader:\n            lr, hr = lr.to(device), hr.to(device)\n            fake_hr = rcan(lr)\n            loss = criterion_pixel(fake_hr, hr)\n            test_loss += loss.item()\n\n    test_loss /= len(test_dataloader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader):.4f}, Test Loss: {test_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-17T09:50:40.738294Z","iopub.execute_input":"2025-03-17T09:50:40.738577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  code for evaluating metric\n# MSE loss\ndef mse(hr, sr):\n    return torch.mean((hr - sr) ** 2)\n# PSNR \ndef psnr(hr, sr):\n    mse_value = mse(hr, sr)\n    if mse_value == 0:\n        return float('inf')  # No difference between images\n    max_pixel = 1.0  # Assuming 8-bit images\n    return 20 * np.log10(max_pixel / np.sqrt(mse_value))\n# SSIM\ndef calculate_ssim(hr, sr):\n    return ssim(hr, sr, data_range=hr.max() - hr.min())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_metric(dataset):\n    device = 'cpu'\n    rcan.eval()\n    rcan.to(device)\n    avg_mse=0.0\n    avg_psnr=0.0\n    avg_ssim=0.0\n    for idx in tqdm(range(len(dataset))):\n        hr_img = dataset.__getitem__(idx)[1].squeeze()\n        lr_img = dataset.__getitem__(idx)[0].unsqueeze(0)\n        fake_hr_img =  rcan(lr_img).detach().numpy().squeeze()\n        avg_mse += mse(hr_img,fake_hr_img)\n        avg_psnr += psnr(hr_img,fake_hr_img)\n        avg_ssim += calculate_ssim(hr_img.detach().numpy(),fake_hr_img)\n    print(f'Average MSE Loss : {avg_mse/len(dataset)}')\n    print(f'Average PSNR : {avg_psnr/len(dataset)}')\n    print(f'Average SSIM : {avg_ssim/len(dataset)}')\n\neval_metric(dataset_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize(model,idx,dataset_test):\n    hr_img = dataset_test.__getitem__(idx)[1].squeeze()\n    lr_img = dataset_test.__getitem__(idx)[0].unsqueeze(0)\n    fake_hr_img =  torch.clamp(model(lr_img),0,1).detach().numpy().squeeze()\n    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n\n    # plot LR Image\n    axes[0].imshow(lr_img.squeeze(), cmap='gray')  # Use cmap='gray' for grayscale images\n    axes[0].set_title(\"Low Resolution (LR)\")\n    axes[0].axis(\"off\")\n    \n    # Plot HR image\n    axes[1].imshow(hr_img.squeeze(), cmap='gray')  # Use cmap='gray' for grayscale images\n    axes[1].set_title(\"High-Resolution (HR)\")\n    axes[1].axis(\"off\")\n    \n    # Plot Fake HR image\n    axes[2].imshow(fake_hr_img.squeeze(), cmap='gray')\n    axes[2].set_title(\"Generated (Fake HR)\")\n    axes[2].axis(\"off\")\n    \n    # Show the images\n    plt.show()\n    print(f'MSE Loss : {mse(hr_img,fake_hr_img)}',end=' || ')\n    print(f'PSNR : {psnr(hr_img,fake_hr_img)}',end=' || ')\n    print(f'SSIM : {calculate_ssim(hr_img.detach().numpy(),fake_hr_img)}')\n\n\nsamples = np.random.randint(0,len(dataset_test)-1,5)\nfor idx in samples:\n    visualize(rcan,idx,dataset_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}